\epigraph{Algebra is generous; she often gives more than is asked of her.}{Jean dâ€™Alembert}

\section{Burnside's Lemma}
The problem we attempt to solve in this section is the following:
\par
We want to create a necklace, that consists of $n$ beads.
Each bead can be one of two different colors.
How many such necklaces can we create.
\par
Note that we want to only consider unique necklaces.
For example, there is only necklace with $n-1$ black beads and one red bead, not $n$ different necklaces, and so on.
\begin{definition} \label{def:groupaction}
  The \textbf{action} of a group $G$ on a set $X$ is a map with particular properties.
  Specifically, it is $\phi: G \times X \rightarrow X$ that satisfies:
  \begin{itemize}
    \item Identity: $\phi(e, x) = x$ where $x \in X$ and $e$ is the identity of $G$.
    \item Compatability: $\phi(g, \phi(h, x)) = \phi(gh, x)$.
  \end{itemize}
\end{definition}
This is where the very famous Rubik's Cube example of groups fits.
The set of all possible states of the Rubik's cube is the set $X$, and the set of cube moves is the group $G$.
\par
Another example of group action is one we have already seen, $S_{n}$, the group of permutation actions of a finite set.
Here, the set of all permutations is the set $X$, and the set of permuation actions is the group.
\par
A similar group is the Dihedral Group of regular polygons, $D_{n}$.
It is the group of symmetries of a regular polygon.
It consists of rotational symmetries and reflection symmetries.
\par
Going back to our necklace problem, consider a set of $2^{n}$ possible necklaces.
We get this number $2^{n}$ by considering two choices of colours for each of the $n$ beads.
\par
Define an equivalence relation on this set as follows: $cRc'$ if there is an element of $D_{n}$ that changes $c$ to $c'$.
The problem of counting the number of necklaces is basically counting the number of such equivalence classes.
We call each such equivalence class an \textbf{orbit}.
The trouble arises since each class is of a different size.
Burnside's Lemma gives us a solution to this problem.
\begin{lemma} \label{lem:burnside}
  Let $G$ be a finite group that acts on $X$.
  The number of orbits, denoted $|X \big/ G|$ is given by
  \begin{align*}
    |X \big/ G| = \frac{1}{|G|} \Sigma_{g \in G} |X^{g}|
  \end{align*}
  where for a particular $g$, $X^{g}$ is the subset of $X$ that is unchanged by $g$.
  For example, $X^{e} = X$, since the identity leaves every element unchanged.
\end{lemma}
\begin{proof}
  The first step we take, is given $x \in X$, to try and find the size of the orbit that $x$ belongs to.
  Consider the set $G_{x} = \{ gx = x | g \in G \}$.
  In other words, this is the set of actions that does not change $x$.
  This is called the stabilizer of $x$.
  This set is a subgroup (proof left as an exercise).
  Therefore, we can quotient $G$ by $G_{x}$ to form a quotient group.
  Consider each element of this quotient group, $G \big/ G_{x}$.
  This element is a set of actions that all map $x$ to the same element, $x'$.
  Thus, the number of elements in the orbit of $x$ is simply the size of the group $G \big/ G_{x}$, which is $\frac{|G|}{|G_{x}|}$ by Lagrange theorem, and is denoted by $|G.x|$.
  \par
  Consider now the sum $\Sigma_{g \in G} |X^{g}|$. This is simply the cardinality of the set $ \{ (g, x) | gx = x, g \in G, x \in X \}$ and can thus be equivalently written as a sum over the elements of $X$.
  This gives us $\Sigma_{g \in G} |X^{g}| = \Sigma_{x \in X} |G.x|$.
  \par
  Substituting, we get $\Sigma_{g \in G} |X^{g}| = |G| \Sigma_{x \in X} \frac{1}{|G.x|}$.
  We now use the fact that $X$ is a disjoint union of all its orbits.
  The sum over $X$ can be reduced as a double summation, one over all the orbits, and an inner summation over all the elements of each orbit.
  Further, the sum $\Sigma_{x \in A} \frac{1}{|G.x|}$ where $A$ is an orbit is clearly 1, since by definition the orbit contains $|G.x|$ elements, which is same for all $x \in A$.
  Thus, we get that the summation $\Sigma_{g \in G} |X^{g}| = |G| \Sigma_{x \in X} \frac{1}{|G.x|} = |G| | X \big/ G|$, which completes the proof.
\end{proof}

\section{Algebraic Geometry}
Algebraic Geometry is the application of abstract algebra to solve geometric problems.
The problem we attempt to solve in this section is to find a proof of the following:
\begin{theorem} \label{theorem:pascals}
  Pascal's theorem: The meets of opposite sides of a hexagon inscribed in a conic are collinear.
\end{theorem}
In other words, if we find the three points of intersections of opposite sides of the hexagon that is inscribed on any conic section, these points will be collinear.
In the next section, we set up a mapping between algebra and geometry, and prove the above \hyperref[theorem:pascals]{theorem} in the section after that.

\subsection{Mapping}
Consider the set $\mathbb{C}^{2}$ and the set $\mathbb{C}[x, y]$.
We build a correspondence between the two.
\par
For \textbf{points} in $\mathbb{C}^{2}$, we have $p = ( \alpha, \beta )$.
In $\mathbb{C}[x, y]$ we can map this to the set of all curves that vanish at $p$.
Let $I$ be the set of all polynomials $A(x, y)$ such that $A(p) = 0$.
\begin{lemma} \label{lem:idealpoint}
  $I$ is a maximal ideal of $\mathbb{C}[x, y]$.
\end{lemma}
\begin{proof} \label{proof:idealpoint}
  Let $I \subsetneq J$.
  Then $B_{\circ}(x, y) \in J$ such that $B_{\circ}(p) \neq 0$.
  Let $S_{J} = \{ \widehat{p} \in \mathbb{C}^{2} | B(\widehat{p}) = 0, \forall B \in J \}$.
  We know that $x - \alpha$ and $y - \beta$ both belong to $J$, since they vanish at $p$.
  Therefore, the only point $S_{J}$ can contain, if at all, is $p$.
  However, $B_{\circ}$ does not vanish at $p$.
  Therefore, $S_{J} = \phi$.
  \par
  We now state without proof and use a theorem that fundamentally establishes the relationship between algebra and geometry.
  \par
  \begin{theorem} \label{theorem:nullstellensatz}
    Hilbert's Nullstellensatz.
    Let $I$ be an ideal of $\mathbb{C}[x, y]$.
    Let $S_{I}$ be the locus of curves in $I$.
    Let $B(x, y)$ be a curve that passes through all the points in $S_{I}$.
    Then $B^{m} \in I$ for some $m \geq 1$.
    If $S_{I} = \phi$, then $m = 1$.
  \end{theorem}
  Continuing with the proof of lemma \ref{lem:idealpoint}, we have $S_{J} = \phi$.
  Every curve passes through $S_{J}$.
  By \hyperref[theorem:nullstellensatz]{Nullstellensatz}, a power of $B$, for all $B \in \mathbb{C}[x ,y], B^{m} \in J$.
  Since $S_{J}$ is $\phi$, $m = 1$.
  Therefore, $I$ is maximal.
\end{proof}

\begin{lemma} \label{lem:maximalpoint}
  Every maximal ideal has a single point as its locus.
\end{lemma}
\begin{proof} \label{proof:maximalpoint}
  Assume that the locus had two or more points.
  We could then add to the ideal all the curves that pass through one of the two points, and get a bigger ideal.
  \par
  Assume that the locus had no points.
  Then, by Nullstellensatz, the ideal is the whole ring.
\end{proof}
Further, the ideal of all curves that pass through the point $p$ is generated by $(x - \alpha)$ and $(y - \beta)$.
\par
Now that we have a mapping for points, we move on to \textbf{curves}.
A good first guess is that curves $A(x, y)$ map to ideals generated by $A(x, y), (A(x, y))$.
We try and prove this.
\begin{proof} \label{proof:curveideal}
  Consider $I_{A} = \{ B(x, y) | B(p) = 0, p \in S_{A} \}, S_{A} = \{ p | A(p) = 0 \}$.
  In other words, $I_{A}$ is the ideal of all curves that are zero at all points along the curve $A(x, y)$.
  \par
  By definition, $(A(x, y)) \subseteq I_{A}$.
  We now need to show that $I_{A} \subseteq (A(x, y))$ to show that $I_{A} = (A(x, y))$.
  \par
  Applying the Nullstellensatz: We have $I = (A(x, y)), S_{I} = S_{A}$ and the set of all $B(x, y) = I_{A}$.
  Thus, a power of every element of $I_{A}$ is in $(A(x, y))$.
  If $A$ is irreducible, then if $B_{1} \times B_{2} \in (A)$, then $A | B_{1} \times B_{2} \Rightarrow A | B_{1}$ or $A | B_{2} \Rightarrow B_{1} \in (A)$ or $B_{2} \in (A)$.
  In way, if $B^{m} \in (A(x, y)), B \in (A(x, y))$.
\end{proof}
The above gives that if irreducible curves map to prime ideals.
\par
Further, consider \textbf{functions defined on the curve} $A(x, y)$.
They can be mapped to $\mathbb{C}[x, y] \big/ (A(x, y))$.
This is called the coordinate ring of $A(x, y)$ and is represented by $\mathrm{T} (A)$.
\par
Finally, \textbf{rational functions defined on the curve} $A(x, y)$ can be mapped to $A(\mathbb{C})$, the field of fractions of $\mathrm{T} (A)$.
This is called the functional field of $A(x, y)$.
\begin{theorem} \label{theorem:coordinateringdd}
  Coordinate rings are Dedekind domains.
\end{theorem}
\begin{proof} \label{proof:coordinateringdd}
  Let $I$ be an ideal of $\mathrm{T} (A)$.
  Elements of $I$ are of the type $p(x, y) + (A(x, y))$.
  Maximal ideals still correspond to points.
  Therefore, every $(B(x, y)) \in \mathrm{T} (A), B \neq 0$, can be written uniquely as a product of prime ideals.
\end{proof}
Armed with this, we move on to the proof of the Pascal's Theorem.
\subsection{Proof of Pascal's Theorem}
Let $F(x, y)$ be a conic, so $deg(F) = 2$.
Consider the hexagon inscribed on the conic.
Let its lines, in sequence, be $l_{1}, l_{2}, l_{3}, l_{4}, l_{5}, l_{6}$.
Let $G = l_{1} l_{3} l_{5}$ and $H = l_{2} l_{4} l_{6}$.
Then $deg(G) = deg(H) = 3$.
Let $R = \mathbb{C}[x, y] \big/ (F, g) = \mathrm{T} (F) \big / G$.
$F$ and $G$ intersect at exactly six points, therefore $\mathbb{C}[x, y] \big/ (F, G)$ is the function defined exactly on those six points.
\begin{lemma} \label{lem:sixpoints}
  $R \cong \mathbb{C} \oplus \mathbb{C} \oplus \mathbb{C} \oplus \mathbb{C} \oplus \mathbb{C} \oplus \mathbb{C}$
\end{lemma}
We have $H \in R$.
In particular, $H = (0, 0, 0, 0, 0, 0)$.
\par
Therefore, $H \in (F, G) \Rightarrow H = AF + BG$ for $A, B \in \mathbb{C}[x, y]$.
$H, G$ have degree three, and $F$ has degree two.
Lets say $deg(A) = d$.
Then $deg(B) = d-1$, since we need the high order terms to cancel.
\par
Let $A_{d}$ be the degree $d$ term of $A$ and $B_{d-1}$ the degree $d-1$ term of $B$.
Define $F_{2}, F_{1}, G_{3}$ similarly.
The highest degree term on the RHS, $A_{d}F_{2} + B_{d-1}G_{3} = 0$.
Assuming that the lines of $G$ are not tangent to $F$ or intersect $F$ only at infinity, it follows that $gcd(F_{2}, G_{3}) = 1$.
Therefore, $B_{d-1} = c F_{2}$ and $A_{d} = -c G_{3}$.
So $H = AF + BG + cGF - cGF = (A + cG)F + (B - cF)G$.
We have written $H$ as a linear combination with different coefficients.
These two coefficients have degree one less than the previous.
This way, we keep reducing the degree till $H = \widehat{A} F + \widehat{B} G$, where $\widehat{A}, \widehat{B}$ have degrees one and zero respectively.
\par
$H$ and $G$ intersect at nine points, six on the conic and three more on the intersections of the opposite sides of the hexagon, outside the conic(the very same three points we want to prove are collinear).
On each of the three outside points, $H = 0, G = 0$, but $F$ is clearly non-zero.
This is only possible if $\widehat{A} = 0$ on all these three points.
However, since $\widehat{A}$ has degree one by construction, $\widehat{A}$ is a line that passes through all those three points.
\par
This completes the proof.
